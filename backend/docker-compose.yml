services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fairpath-backend
    ports:
      - "${PORT:-8000}:8000"
    environment:
      - PORT=8000
      - ENV_MODE=production
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - CORS_ORIGINS=${CORS_ORIGINS:-https://fair-path.vercel.app,http://localhost:3000,http://localhost:5173}
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE:-60}
      - RATE_LIMIT_PER_HOUR=${RATE_LIMIT_PER_HOUR:-1000}
      - RATE_LIMIT_PER_DAY=${RATE_LIMIT_PER_DAY:-10000}
      - MAX_REQUEST_SIZE=${MAX_REQUEST_SIZE:-1048576}
      - MAX_UPLOAD_SIZE=${MAX_UPLOAD_SIZE:-10485760}
      - OPENAI_TIMEOUT=${OPENAI_TIMEOUT:-30}
      - OPENAI_MAX_RETRIES=${OPENAI_MAX_RETRIES:-2}
      - OPENAI_RETRY_DELAY=${OPENAI_RETRY_DELAY:-1.0}
    volumes:
      # Mount artifacts directory if you want to persist model updates
      - ./artifacts:/app/artifacts
      # Mount data directory if you want to persist data updates
      - ./data:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - fairpath-network

networks:
  fairpath-network:
    driver: bridge

